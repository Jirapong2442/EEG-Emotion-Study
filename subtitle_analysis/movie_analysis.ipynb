{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence reconstruction from srt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C:/Users/NA/Saved Games/eeg_study/modified_500_days_of_summer_subtitle.srt\"\n",
    "path = \"C:/Users/NA/Saved Games/eeg_study/subtitle_all/pulp_fiction_subtitle.srt\"\n",
    "#path = \"C:/Users/NA/Saved Games/eeg_study/subtitle_all/the_usual_suspects_subtitle.srt\"\n",
    "with open(path, \"r\", encoding='utf-8-sig') as f:\n",
    "    string = f.read()\n",
    "    lines = string.split(\"\\n\")\n",
    "    time_arr = []\n",
    "    subtitles = []\n",
    "    first_text = True\n",
    "    continueable = False\n",
    "    for line in lines:\n",
    "        if (len(line) < 5 and line.isdigit()) or len(line) == 0:\n",
    "            continue\n",
    "            \n",
    "        if \" --> \" not in line:\n",
    "            text = line.strip()\n",
    "            if continueable : # add subtitle with ... place holder of differnt time annotation\n",
    "                last_subtitles = subtitles[-1]\n",
    "                subtitles.pop()\n",
    "                subtitles.append((last_subtitles + \" \" + text))\n",
    "\n",
    "                last_time = time_arr[-2]\n",
    "                time_arr.pop()\n",
    "                time_arr.pop()\n",
    "                time_arr.append((last_time[0], end_time))\n",
    "                continueable = False\n",
    "                first_text = False \n",
    "\n",
    "            else:\n",
    "                if \"...\" in line and not first_text:\n",
    "                    text = text.replace(\"...\", \"\")\n",
    "                    continueable = True\n",
    "                elif \"...\" in line and first_text: # add this to skip the continuable if \"\"...\" presence only in the line\n",
    "                    text = text.replace(\"...\", \"\")\n",
    "                    \n",
    "                if first_text  :\n",
    "                    subtitles.append(text)\n",
    "                    first_text = False\n",
    "                else: # add subtitle between line of the same time annotation\n",
    "                    last_subtitles = subtitles[-1]\n",
    "                    subtitles.pop()\n",
    "                    subtitles.append((last_subtitles + \" \" + text))\n",
    "\n",
    "            # to clean data with only time/subtitle\n",
    "            if len(subtitles) != len(time_arr):\n",
    "                print(text) \n",
    "                print(start_time)\n",
    "                print(f\"len subtitle is {len(subtitles)}\")\n",
    "                print(f\"len time ios {len(time_arr)}\")\n",
    "\n",
    "        else:\n",
    "            first_text = True\n",
    "            time = line.split(\" --> \")\n",
    "            start = time[0].split(\",\")[0].split(\":\")\n",
    "            end = time[1].split(\",\")[0].split(\":\")\n",
    "            start_ms = time[0].split(\",\")[1]\n",
    "            end_ms = time[1].split(\",\")[1]\n",
    "            start_time = int(start[0]) * 3600 + int(start[1]) * 60 + float(start[2]) + float(start_ms) / 1000\n",
    "            end_time = int(end[0]) * 3600 + int(end[1]) * 60 + float(end[2]) + float(end_ms) / 1000\n",
    "            time_arr.append((start_time, end_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_arr = pd.DataFrame({\n",
    "    \"start_time\": [t[0] for t in time_arr],\n",
    "    \"end_time\": [t[1] for t in time_arr],\n",
    "    \"text\": subtitles\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.40</td>\n",
       "      <td>30.711</td>\n",
       "      <td>Forget it. It's too risky. I'm through doing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.80</td>\n",
       "      <td>34.077</td>\n",
       "      <td>You always say that. The same thing every time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.20</td>\n",
       "      <td>35.998</td>\n",
       "      <td>\"I'm through, never again, too dangerous.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.12</td>\n",
       "      <td>38.475</td>\n",
       "      <td>I know that's what I always say. I'm always ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.56</td>\n",
       "      <td>41.791</td>\n",
       "      <td>- You forget about it in a day or two. - The d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>8541.08</td>\n",
       "      <td>8543.879</td>\n",
       "      <td>I'm trying real hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>8543.96</td>\n",
       "      <td>8546.110</td>\n",
       "      <td>to be the shepherd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>8560.84</td>\n",
       "      <td>8562.638</td>\n",
       "      <td>Go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>8579.64</td>\n",
       "      <td>8581.950</td>\n",
       "      <td>I think we should be leaving now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>8582.04</td>\n",
       "      <td>8584.839</td>\n",
       "      <td>- Yeah, that's probably a good idea.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_time  end_time                                               text\n",
       "0          27.40    30.711  Forget it. It's too risky. I'm through doing t...\n",
       "1          30.80    34.077    You always say that. The same thing every time.\n",
       "2          34.20    35.998         \"I'm through, never again, too dangerous.\"\n",
       "3          36.12    38.475  I know that's what I always say. I'm always ri...\n",
       "4          38.56    41.791  - You forget about it in a day or two. - The d...\n",
       "...          ...       ...                                                ...\n",
       "1947     8541.08  8543.879                               I'm trying real hard\n",
       "1948     8543.96  8546.110                                to be the shepherd.\n",
       "1949     8560.84  8562.638                                                Go.\n",
       "1950     8579.64  8581.950                  I think we should be leaving now.\n",
       "1951     8582.04  8584.839               - Yeah, that's probably a good idea.\n",
       "\n",
       "[1952 rows x 3 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(r'\\W+', ' ', sentence)  # Remove symbols/punctuation\n",
    "    sentence = sentence.lower()               # Lowercase\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)  # Remove extra spaces\n",
    "    return sentence.strip()  \n",
    "sentence_arr['text'] = sentence_arr['text'].apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.40</td>\n",
       "      <td>30.711</td>\n",
       "      <td>forget it it s too risky i m through doing tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.80</td>\n",
       "      <td>34.077</td>\n",
       "      <td>you always say that the same thing every time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.20</td>\n",
       "      <td>35.998</td>\n",
       "      <td>i m through never again too dangerous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.12</td>\n",
       "      <td>38.475</td>\n",
       "      <td>i know that s what i always say i m always rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.56</td>\n",
       "      <td>41.791</td>\n",
       "      <td>you forget about it in a day or two the days o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>8541.08</td>\n",
       "      <td>8543.879</td>\n",
       "      <td>i m trying real hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>8543.96</td>\n",
       "      <td>8546.110</td>\n",
       "      <td>to be the shepherd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>8560.84</td>\n",
       "      <td>8562.638</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>8579.64</td>\n",
       "      <td>8581.950</td>\n",
       "      <td>i think we should be leaving now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>8582.04</td>\n",
       "      <td>8584.839</td>\n",
       "      <td>yeah that s probably a good idea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_time  end_time                                               text\n",
       "0          27.40    30.711  forget it it s too risky i m through doing tha...\n",
       "1          30.80    34.077      you always say that the same thing every time\n",
       "2          34.20    35.998              i m through never again too dangerous\n",
       "3          36.12    38.475  i know that s what i always say i m always rig...\n",
       "4          38.56    41.791  you forget about it in a day or two the days o...\n",
       "...          ...       ...                                                ...\n",
       "1947     8541.08  8543.879                               i m trying real hard\n",
       "1948     8543.96  8546.110                                 to be the shepherd\n",
       "1949     8560.84  8562.638                                                 go\n",
       "1950     8579.64  8581.950                   i think we should be leaving now\n",
       "1951     8582.04  8584.839                   yeah that s probably a good idea\n",
       "\n",
       "[1952 rows x 3 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label text with RoBERTa transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from scipy.special import softmax\n",
    "\n",
    "#load model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model_sentiment = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply model output probability for each sentiment\n",
    "all_scores = []\n",
    "input_vector = []\n",
    "for sentence in sentence_arr['text']:\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "    output = model_sentiment(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the most dominat probability and make new column for class\n",
    "score_roberta = pd.DataFrame(all_scores, columns=['negative', 'neutral', 'positive'])\n",
    "score_roberta['label'] = score_roberta.apply(lambda x: x.idxmax(), axis=1)\n",
    "score_roberta['label'] = score_roberta['label'].map({'neutral': 0, 'negative': -1, 'positive': 1})\n",
    "#score_roberta['label'].to_csv(\"score_roberta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment = []\n",
    "for sentence in sentence_arr['text']:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    sentiment.append(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_vader = pd.DataFrame(sentiment)\n",
    "score_vader['label'] = score_vader['compound'].apply(lambda x: 1 if x >= 0.05 else (-1 if x <= -0.05 else 0))\n",
    "#score_vader['label'].to_csv(\"score_vader.csv\")\n",
    "# 0 neutral, 1 negative, 2 positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "sentiment_tb = []\n",
    "for sentence in sentence_arr['text']:\n",
    "    object_ = TextBlob(sentence)\n",
    "    sentiment_tb.append(object_.sentiment.polarity)\n",
    "sentiment_tb = pd.Series(sentiment_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_textblob = sentiment_tb.apply(lambda x: 1 if x >= 0.15 else (-1 if x <= -0.15 else 0))\n",
    "#score_textblob.to_csv(\"score_textblob.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>vader</th>\n",
       "      <th>roberta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.40</td>\n",
       "      <td>30.711</td>\n",
       "      <td>forget it it s too risky i m through doing tha...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.80</td>\n",
       "      <td>34.077</td>\n",
       "      <td>you always say that the same thing every time</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.20</td>\n",
       "      <td>35.998</td>\n",
       "      <td>i m through never again too dangerous</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.12</td>\n",
       "      <td>38.475</td>\n",
       "      <td>i know that s what i always say i m always rig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.56</td>\n",
       "      <td>41.791</td>\n",
       "      <td>you forget about it in a day or two the days o...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>8541.08</td>\n",
       "      <td>8543.879</td>\n",
       "      <td>i m trying real hard</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>8543.96</td>\n",
       "      <td>8546.110</td>\n",
       "      <td>to be the shepherd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>8560.84</td>\n",
       "      <td>8562.638</td>\n",
       "      <td>go</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>8579.64</td>\n",
       "      <td>8581.950</td>\n",
       "      <td>i think we should be leaving now</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>8582.04</td>\n",
       "      <td>8584.839</td>\n",
       "      <td>yeah that s probably a good idea</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1952 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_time  end_time                                           sentence  \\\n",
       "0          27.40    30.711  forget it it s too risky i m through doing tha...   \n",
       "1          30.80    34.077      you always say that the same thing every time   \n",
       "2          34.20    35.998              i m through never again too dangerous   \n",
       "3          36.12    38.475  i know that s what i always say i m always rig...   \n",
       "4          38.56    41.791  you forget about it in a day or two the days o...   \n",
       "...          ...       ...                                                ...   \n",
       "1947     8541.08  8543.879                               i m trying real hard   \n",
       "1948     8543.96  8546.110                                 to be the shepherd   \n",
       "1949     8560.84  8562.638                                                 go   \n",
       "1950     8579.64  8581.950                   i think we should be leaving now   \n",
       "1951     8582.04  8584.839                   yeah that s probably a good idea   \n",
       "\n",
       "      TextBlob  vader  roberta  \n",
       "0           -1     -1       -1  \n",
       "1            0      0       -1  \n",
       "2           -1      1       -1  \n",
       "3            1      0        1  \n",
       "4            0     -1       -1  \n",
       "...        ...    ...      ...  \n",
       "1947        -1     -1        0  \n",
       "1948         0      0        0  \n",
       "1949         0      0        0  \n",
       "1950         0      0       -1  \n",
       "1951         1      1        1  \n",
       "\n",
       "[1952 rows x 6 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_all = pd.DataFrame(score_textblob, columns= ['TextBlob'])\n",
    "score_all['vader'] = score_vader['label']\n",
    "score_all['roberta'] = score_roberta['label']\n",
    "score_all.insert(0, 'sentence', sentence_arr['text'])\n",
    "score_all.insert(0, 'start_time', sentence_arr['start_time'])\n",
    "score_all.insert(1, 'end_time', sentence_arr['end_time'])\n",
    "score_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = score_all['TextBlob'].value_counts()\n",
    "roberta = score_all['roberta'].value_counts()\n",
    "vader = score_all['vader'].value_counts()\n",
    "\n",
    "# Step 2: Combine into a DataFrame\n",
    "# This handles missing categories automatically\n",
    "counts_df = pd.concat([tb, roberta, vader], axis=1, keys=['TextBlob', 'roberta', 'vader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>roberta</th>\n",
       "      <th>vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1217</td>\n",
       "      <td>1047</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>373</td>\n",
       "      <td>653</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>362</td>\n",
       "      <td>252</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TextBlob  roberta  vader\n",
       " 0      1217     1047    867\n",
       "-1       373      653    527\n",
       " 1       362      252    558"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "out_name= \"pulpFiction\"\n",
    "out_path = \"./image_output/\"\n",
    "csv_path = './csv_output/'\n",
    "# Create plot\n",
    "ax = counts_df.plot(kind='bar', \n",
    "                   figsize=(10, 6),\n",
    "                   rot=0)  # Keep sentiment labels horizontal\n",
    "\n",
    "# Add labels and title\n",
    "plt.title( out_name + 'Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add value labels\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_path,out_name)+ '.jpg')\n",
    "plt.show()\n",
    "\n",
    "score_all.to_csv(os.path.join(csv_path,out_name)+ '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformer mpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7112\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7059\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:07:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "X = embedding_mpnet\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7166\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7005\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:07:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "X = embedding_mpnet\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "textB\n",
      "0    786\n",
      "2    353\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7380\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7594\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:07:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7112\n"
     ]
    }
   ],
   "source": [
    "X = embedding_mpnet\n",
    "y = sentence_arr['textB']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_all.to_csv('ShawShankRedemption_class_of_sentence.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(score_vader['label'].values, score_roberta['label'].values)\n",
    "sim = sum(x == y for x, y in zip(score_vader['label'], score_roberta['label'] )) / len(score_vader['label'])\n",
    "score = jaccard_score(score_vader['label'].values, score_roberta['label'].values, average='weighted')\n",
    "\n",
    "accuracy_tb_v = accuracy_score(score_vader['label'].values, score_textblob)\n",
    "sim_tb_v = sum(x == y for x, y in zip(score_vader['label'], score_textblob )) / len(score_vader['label'])\n",
    "score_tb_v = jaccard_score(score_vader['label'].values, score_textblob, average='weighted')\n",
    "\n",
    "accuracy_tb_r = accuracy_score(score_textblob, score_roberta['label'].values)\n",
    "sim_tb_r = sum(x == y for x, y in zip(score_textblob, score_roberta['label'] )) / len(score_roberta['label'])\n",
    "score_tb_r = jaccard_score(score_textblob.values, score_roberta['label'].values, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score vader roberta is 0.6168674698795181\n",
      "jaccard score vader roberta is 0.439582572855067\n",
      "accuracy score vader roberta is 0.6168674698795181\n"
     ]
    }
   ],
   "source": [
    "print(f\"similarity score vader roberta is {sim}\")\n",
    "print(f\"jaccard score vader roberta is {score}\")\n",
    "print(f\"accuracy score vader roberta is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score vader textblob is 0.6404028436018957\n",
      "jaccard score vader textblob is 0.45481739143295324\n",
      "accuracy score vader textblob is 0.6404028436018957\n"
     ]
    }
   ],
   "source": [
    "print(f\"similarity score vader textblob is {accuracy_tb_v}\")\n",
    "print(f\"jaccard score vader textblob is {score_tb_v}\")\n",
    "print(f\"accuracy score vader textblob is {sim_tb_v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score textblob roberta is 0.6433649289099526\n",
      "jaccard score textblob roberta is 0.6433649289099526\n",
      "accuracy score textblob roberta is 0.5159642440229745\n"
     ]
    }
   ],
   "source": [
    "print(f\"similarity score textblob roberta is {accuracy_tb_r}\")\n",
    "print(f\"jaccard score textblob roberta is {sim_tb_r}\")\n",
    "print(f\"accuracy score textblob roberta is {score_tb_r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## emotion analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change word to vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence / word tokenization and embeddingh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "def sentence_to_vec(sentence, model, vector_size=300):\n",
    "    words = sentence.lower().split()  \n",
    "    #tokens = [re.sub(r'\\W+', '', token) for token in words] \n",
    "    word_vectors = [model[word] for word in words if word in model.key_to_index]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# load model to embed the word into vector\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.downloader import load\n",
    "model_w2v = load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in model: ['this', 'is', 'story', 'boy', 'meets', 'girl']\n",
      "Tokens 2 in model: ['the', 'boy', 'tom', 'hansen', 'new', 'jersey', 'grew', 'up', 'believing', 'that', 'hed', 'never', 'truly', 'be', 'happy', 'until', 'the', 'day', 'he', 'met', 'the', 'one']\n"
     ]
    }
   ],
   "source": [
    "# check word in dict\n",
    "tokens = ['this', 'is', 'a', 'story', 'of', 'boy', 'meets', 'girl']\n",
    "tokens2 = ['the', 'boy', 'tom', 'hansen', 'of', 'margate', 'new', 'jersey', 'grew', 'up', 'believing', 'that', 'hed',\n",
    "            'never', 'truly', 'be', 'happy', 'until', 'the', 'day', 'he', 'met', 'the', 'one']\n",
    "valid_tokens = [token for token in tokens if token in model_w2v]\n",
    "print(\"Tokens in model:\", valid_tokens)\n",
    "\n",
    "valid_tokens2 = [token for token in tokens2 if token in model_w2v]\n",
    "print(\"Tokens 2 in model:\", valid_tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distolbert-tokenization and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "def get_cls_embeddings_from_series(text_series, tokenizer,model, max_length=128, batch_size=1):\n",
    "    \"\"\"\n",
    "    Converts a Pandas Series of text into a NumPy array of CLS embeddings using DistilBERT.\n",
    "    where CLS is used in the model as a sentence embedding. \n",
    "\n",
    "    Parameters:\n",
    "        text_series (pd.Series): Series of text strings\n",
    "        max_length (int): Maximum token length per sentence\n",
    "        batch_size (int): Batch size for processing (optional, useful for large sets)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (n_samples, 768) containing CLS embeddings\n",
    "    \"\"\"\n",
    "    cls_embeddings = []\n",
    "\n",
    "    for text in text_series:\n",
    "        encoded_input = tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "\n",
    "        cls_vec = output.last_hidden_state[:, 0, :]  # [1, 768]\n",
    "        #cls_embeddings.append(cls_vec.squeeze(0).numpy())  # [768]\n",
    "        cls_embeddings.append(np.expand_dims(cls_vec.squeeze(0).numpy(), axis=0))\n",
    "\n",
    "    return np.vstack(cls_embeddings) # shape: [num_sentences, 768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment_tokenization from roberta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_tokenization\n",
    "model_cardiff = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer_ = AutoTokenizer.from_pretrained(model_cardiff)\n",
    "\n",
    "def car_diff_embed(text_series, max_length=128, batch_size=1):\n",
    "\n",
    "    car_diff = []\n",
    "    for text in text_series:\n",
    "\n",
    "        embedding_cardiff = tokenizer_(\n",
    "            text,\n",
    "            return_tensors='pt',       # Return PyTorch tensors\n",
    "            padding='max_length',      # Pad all to the same max_length\n",
    "            truncation=True,           # Truncate if over max_length\n",
    "            max_length=162      \n",
    "        )\n",
    "\n",
    "        car_diff.append(embedding_cardiff['input_ids'].numpy())\n",
    "\n",
    "    return car_diff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6997454 ,  0.15458025, -0.01059891, ...,  0.47170144,\n",
       "         0.93815315, -0.41023418],\n",
       "       [-0.54252654,  0.6246307 ,  0.03168805, ..., -0.15648341,\n",
       "        -0.71036536, -0.00857123]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run embedding and tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilbert fine-tuned with standford dataset for sentiment analysis SST2\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "tokenizer_BERT = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_BERT = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_BERT.eval()\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer_sentence_finetuned = AutoTokenizer.from_pretrained(model_name)\n",
    "model_sentence_finetuned = AutoModel.from_pretrained(model_name)  \n",
    "model_sentence_finetuned.eval()\n",
    "\n",
    "\n",
    "\n",
    "sentence_arr['embedding_w2v'] = sentence_arr['text'].apply(lambda x: np.array(sentence_to_vec(x, model_w2v)))\n",
    "embedding_tfm = get_cls_embeddings_from_series(sentence_arr['text'], tokenizer= tokenizer_BERT, model= model_BERT)\n",
    "embedding_sst = get_cls_embeddings_from_series(sentence_arr['text'], tokenizer= tokenizer_sentence_finetuned, model= model_sentence_finetuned)\n",
    "\n",
    "embedding_cardiff = np.squeeze(np.array(car_diff_embed(sentence_arr['text'])))\n",
    "\n",
    "sentence_arr['vader'] = score_vader['label']\n",
    "sentence_arr['roberta'] = score_roberta['label']\n",
    "sentence_arr['textB'] = score_textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\NA\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_miniLM = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model_mpnet = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embedding_miniLM = model_miniLM.encode(sentence_arr['text'].values)\n",
    "embedding_mpnet = model_mpnet.encode(sentence_arr['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification sentiment with word vector as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 300) | Val size: (187, 300) | Test size: (187, 300)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7059\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7914\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:06:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack(sentence_arr['embedding_w2v'].values)\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 300) | Val size: (187, 300) | Test size: (187, 300)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.6310\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.6684\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:07:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6578\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack(sentence_arr['embedding_w2v'].values)\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 300) | Val size: (187, 300) | Test size: (187, 300)\n",
      "textB\n",
      "0    786\n",
      "2    353\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7968\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.8021\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:07:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack(sentence_arr['embedding_w2v'].values)\n",
    "y = sentence_arr['textB']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.5294\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.4920\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:07:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5401\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = embedding_tfm\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 162) | Val size: (187, 162) | Test size: (187, 162)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:07:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5508\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.5775\n",
      "\n",
      "=== Training: XGBoost ===\n",
      "Validation Accuracy: 0.5455\n"
     ]
    }
   ],
   "source": [
    "X = embedding_cardiff\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 162) | Val size: (187, 162) | Test size: (187, 162)\n",
      "textB\n",
      "0    786\n",
      "2    353\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:07:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6364\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.6310\n",
      "\n",
      "=== Training: XGBoost ===\n",
      "Validation Accuracy: 0.6524\n"
     ]
    }
   ],
   "source": [
    "X = embedding_cardiff\n",
    "y = sentence_arr['textB']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 384) | Val size: (187, 384) | Test size: (187, 384)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.6952\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.6738\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:55:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6684\n"
     ]
    }
   ],
   "source": [
    "X = embedding_miniLM\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 384) | Val size: (187, 384) | Test size: (187, 384)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7273\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7166\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:56:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7219\n"
     ]
    }
   ],
   "source": [
    "X = embedding_miniLM\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 384) | Val size: (187, 384) | Test size: (187, 384)\n",
      "textB\n",
      "0    786\n",
      "2    353\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7487\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7701\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:06:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "X = embedding_miniLM\n",
    "y = sentence_arr['textB']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformer mpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7112\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7059\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:07:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "X = embedding_mpnet\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7166\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7005\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:07:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "X = embedding_mpnet\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "textB\n",
      "0    786\n",
      "2    353\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7380\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7594\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:07:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7112\n"
     ]
    }
   ],
   "source": [
    "X = embedding_mpnet\n",
    "y = sentence_arr['textB']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformer fine-tunedsst\n",
    "currently perform the best for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7594\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7273\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:20:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7594\n"
     ]
    }
   ],
   "source": [
    "X = embedding_sst\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7166\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7112\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:20:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "X = embedding_sst\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 768) | Val size: (187, 768) | Test size: (187, 768)\n",
      "textB\n",
      "0    786\n",
      "2    353\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.7594\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.7059\n",
      "\n",
      "=== Training: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:20:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7487\n"
     ]
    }
   ],
   "source": [
    "X = embedding_sst\n",
    "y = sentence_arr['textB']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 3) | Val size: (187, 3) | Test size: (187, 3)\n",
      "roberta\n",
      "0    721\n",
      "2    270\n",
      "1    254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.9893\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.9786\n",
      "\n",
      "=== Training: XGBoost ===\n",
      "Validation Accuracy: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:17:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "X = score_roberta.iloc[:,:-1]\n",
    "y = sentence_arr['roberta']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245, 1)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(score_vader.iloc[:,3],axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (871, 1) | Val size: (187, 1) | Test size: (187, 1)\n",
      "vader\n",
      "0    527\n",
      "2    514\n",
      "1    204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training: Logistic Regression ===\n",
      "Validation Accuracy: 0.9572\n",
      "\n",
      "=== Training: SVM (linear) ===\n",
      "Validation Accuracy: 0.9947\n",
      "\n",
      "=== Training: XGBoost ===\n",
      "Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NA\\.conda\\envs\\eeg_study\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:22:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "X = np.expand_dims(score_vader.iloc[:,3],axis = 1)\n",
    "y = sentence_arr['vader']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "print(\"Train size:\", X_train.shape, \"| Val size:\", X_val.shape, \"| Test size:\", X_test.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
    "    \"SVM (linear)\": SVC(kernel='rbf', C=1.0, probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=4, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# === Train and evaluate each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    #print(\"Classification Report:\")\n",
    "    #print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
